# -*- encoding:cp1251 -*-
from __future__ import division

import operator, re

def grouped(s):
    return u"(?:%s)" % s

PGERUND    = grouped(u"(?:(?:ס)?טר)?ג(?:[ט]|(?=[א]))")
ADJECTIVE  = grouped(u"[ולי][וטמ]|טל[ט]|מד[ומ]|ףל[ומ]|ץ[ט]|‏[מוף‏]|[א]")
PARTICIPLE = grouped(u"ש‏ף|רג[ט]|(?:לו|םם|רג|ש‏?)(?=[א])")
ADJECTIVAL = "%s%s?" % (ADJECTIVE, PARTICIPLE)
REFLEXIVE  = grouped(u"[]ס")
VERB1      = u"(?:א[כם]|וע[וי]|טכ|כ|י|לו|ם|מ(?:כ|םם?)|ע[ו‏]|ם|(?:ע|רו))(?=[א])"
VERB2      = u"א(?:כ[ט]|םו)|וע(?:ט|י[וף])|טכ[ט]|י[וף]|כ[ט]|ל[ט]|םו|מ(?:םו|כ[ט])|ע(?:[ט]|[ו‏]ף)|םו|(?:רט|ע[ט])|‏ף?"
VERB       = grouped(VERB1 + '|' + VERB2)
NOUN       = grouped(u"[אמף]|ג[ומ]|ו[ט]?|טל(?:א|ט?)|ט[וט]?|י(?:[מט]|וט?)?|ל(?:[אמ]|[ו]ט?)|ץ(?:א|ט?)|‏[ט]?|[ט]?")
SUPERLATIVE  = grouped(u"ו?ריו")
DERIVATIONAL = u"?עסמ"

def regex(s):
    return re.compile(s, re.UNICODE)

VOVELS = u"אוטמף‎‏"
rv_re = regex(ur"([^@]*[@])(.*)".replace('@', VOVELS))
r2_re = regex(ur"([@]*[^@]+[@]+[^@])(.*)".replace('@', VOVELS))
word_re = regex(ur"^[א-]+$")

STEP12 = u"(%s|%s?(?:%s|%s|%s)?)ט?(.*)" % (PGERUND, REFLEXIVE, ADJECTIVAL, VERB, NOUN)
re_step12 = regex(STEP12)

STEP3 = "(%s)?(.*)" % DERIVATIONAL
re_step3 = regex(STEP3)

STEP4 = u"(|%s?(?:ם(?=ם))?)?(.*)" % SUPERLATIVE
re_step4 = regex(STEP4)

def stem(word):
    word = word.lower().replace(u'¸', u'ו')
    if not word_re.match(word): return word
    rv_match = rv_re.match(word)
    if not rv_match: return word
    prefix, rv = rv_match.groups()
    revrv = rv[::-1]
    ending, rest = re_step12.match(revrv).groups()
    ending3, rest3 = re_step3.match(rest).groups()
    if ending3:
        r2_match = r2_re.match(rv)
        if r2_match:
            prefix2, r2 = r2_match.groups()
            if len(prefix2) + len(ending3) < len(rv):
                rest = rest3
    ending4, rest = re_step4.match(rest).groups()
    return prefix + rest[::-1]

endings = u"""
א אל אלט אץ א ו וג ודמ וו וי ול ולף ט טו טט טי טל טלט טץ ט י מ מג
מדמ מו מי מל מלף ף ף‏  ו י ל לט ץ  ‏ ‏ ‏‏  ל לט ץ  ¸ל
""".split()

endings_1 = set(x for x in endings if len(x) == 1)
endings_2 = set(x for x in endings if len(x) == 2)
endings_3 = set(x for x in endings if len(x) == 3)

def normalize(word):
    size = len(word)
    if size > 5 and word[-3:] in endings_3: return word[:-3]
    if size > 4 and word[-2:] in endings_2: return word[:-2]
    if size > 3 and word[-1:] in endings_1: return word[:-1]
    return word

class Filter(object):
    token_re = re.compile(r'(\w|\$)+', re.UNICODE)
    def __init__(self):
        self.all = {}
        self.spam = {}
        self.all_count = self.spam_count = 0
    def tokenize(self, message):
        for match in self.token_re.finditer(message):
            yield normalize(match.group().lower())         
    def train(self, is_spam, message):
        self.all_count += 1
        if is_spam: self.spam_count += 1
        for token in set(self.tokenize(message)):
            self.all[token] = self.all.get(token, 0) + 1
            if is_spam: self.spam[token] = self.spam.get(token, 0) + 1
    def estimate(self, message):
        all_count = self.all_count + 1
        if not all_count: return 1
        spam_count = self.spam_count
        result = spam_count / all_count
        getall, getspam = self.all.get, self.spam.get
        for token in set(self.tokenize(message)):
            token_count = getall(token, 0)
            if token_count < 2: continue
            tokenspam_count = getspam(token, 0)
            numerator = (tokenspam_count or 0.1) * all_count
            denominator = token_count * spam_count
            result *= numerator / denominator
        return result
